# the wandb project name
task_type: warm_up
# the path of the model to be used for warm-up (student)
model_name_or_path: 
# the path to save the warm-up checkpoint
output_dir: 
# the path of the warm-up dataset
warm_up_dataset_path: 
tokenizer_max_length: 1024

# training parameters
training:
  num_train_epochs: 1
  eval_strategy: "no"
  eval_steps: 30
  save_strategy: "no"
  save_steps: 90
  logging_strategy: "steps"
  logging_steps: 2
  load_best_model_at_end: False
  save_total_limit: 1
  batch_size: 2
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 2
  gradient_accumulation_steps: 2

  optimizer:
    learning_rate: 5e-6
    weight_decay: 0.0
  scheduler:
    type: "warmup_stable_decay"
    warmup_ratio: 1.0
    stable_ratio: 0.0
    decay_ratio: 0.0
    min_lr_ratio: 1.0

# the number of gpus to use for training
num_gpus:
